{"cells":[{"cell_type":"code","execution_count":null,"id":"d44acbcc-20e6-41a1-bad9-fb94fdbb344b","metadata":{"id":"d44acbcc-20e6-41a1-bad9-fb94fdbb344b"},"outputs":[],"source":["!pip install -q streamlit"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"id":"1TdJGhWDZR6c"},"id":"1TdJGhWDZR6c","execution_count":null,"outputs":[]},{"cell_type":"code","source":["directory = \"./gdrive/My Drive/style-transfer\"\n"],"metadata":{"id":"Xlkm9_51Xt4y"},"id":"Xlkm9_51Xt4y","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"c014522b-d5fd-4117-a4b3-d5940eeb5b0b","metadata":{"id":"c014522b-d5fd-4117-a4b3-d5940eeb5b0b"},"outputs":[],"source":["%%writefile app.py\n","\n","import os\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","import streamlit as st\n","from tensorflow.keras.applications import vgg19\n","import matplotlib.pyplot as plt\n","from PIL import Image as PILImage\n","\n","\n","def NST(content_img , style_img):\n","\n","    directory = \"./gdrive/My Drive/style-transfer\"\n","\n","    base_image_path = content_img\n","    style_reference_image_path = style_img\n","    content_image = keras.utils.load_img(base_image_path)\n","    style_image = keras.utils.load_img(style_reference_image_path)\n","\n","    width, height = tf.keras.utils.load_img(base_image_path).size\n","    img_nrows = 400\n","    img_ncols = int(width * img_nrows / height)\n","\n","    def preprocess_image(image_path):\n","        img = keras.utils.load_img(image_path, target_size=(img_nrows, img_ncols))\n","        img = keras.utils.img_to_array(img)\n","        img = np.expand_dims(img, axis=0)\n","        img = vgg19.preprocess_input(img)\n","        return tf.convert_to_tensor(img)\n","\n","    def deprocess_image(x):\n","        x = x.reshape((img_nrows, img_ncols, 3))\n","        x[:, :, 0] += 103.939\n","        x[:, :, 1] += 116.779\n","        x[:, :, 2] += 123.68\n","        x = x[:, :, ::-1]\n","        x = np.clip(x, 0, 255).astype(\"uint8\")\n","        return x\n","\n","    def gram_matrix(x):\n","        x = tf.transpose(x, (2, 0, 1))\n","        features = tf.reshape(x, (tf.shape(x)[0], -1))\n","        gram = tf.matmul(features, tf.transpose(features))\n","        return gram\n","\n","    def style_loss(style, combination):\n","        S = gram_matrix(style)\n","        C = gram_matrix(combination)\n","        channels = 3\n","        size = img_nrows * img_ncols\n","        return tf.reduce_sum(tf.square(S - C)) / (4.0 * (channels**2) * (size**2))\n","\n","    def content_loss(base, combination):\n","        channels = 3\n","        size = img_nrows * img_ncols\n","        return tf.reduce_sum(tf.square(combination - base)/ (4.0 * (channels) * (size)))\n","\n","    def total_variation_loss(x):\n","        a = tf.square(x[:, : img_nrows - 1, : img_ncols - 1, :] - x[:, 1:, : img_ncols - 1, :])\n","        b = tf.square(x[:, : img_nrows - 1, : img_ncols - 1, :] - x[:, : img_nrows - 1, 1:, :])\n","        return tf.reduce_sum(tf.pow(a + b, 1.25))\n","\n","    model = vgg19.VGG19(weights=\"imagenet\", include_top=False)\n","\n","    outputs_dict = dict([(layer.name, layer.output) for layer in model.layers])\n","\n","    for layer in model.layers:\n","        print (layer.name)\n","\n","\n","    feature_extractor = keras.Model(inputs=model.inputs, outputs=outputs_dict)\n","\n","    style_layer_names = [\"block1_conv1\", \"block2_conv1\", \"block3_conv1\", \"block4_conv1\", \"block5_conv1\"]\n","    content_layer_name = \"block5_conv2\"\n","\n","    total_variation_weight = 1e-6\n","    style_weight = 1e-6\n","    content_weight = 2.5e-8\n","\n","    def compute_loss(combination_image, base_image, style_reference_image):\n","        input_tensor = tf.concat([base_image, style_reference_image, combination_image], axis=0)\n","        features = feature_extractor(input_tensor)\n","        loss = tf.zeros(shape=())\n","        layer_features = features[content_layer_name]\n","        base_image_features = layer_features[0, :, :, :]\n","        combination_features = layer_features[2, :, :, :]\n","        loss = loss + content_weight * content_loss(base_image_features, combination_features)\n","        for layer_name in style_layer_names:\n","            layer_features = features[layer_name]\n","            style_reference_features = layer_features[1, :, :, :]\n","            combination_features = layer_features[2, :, :, :]\n","            sl = style_loss(style_reference_features, combination_features)\n","            loss += (style_weight / len(style_layer_names)) * sl\n","        loss += total_variation_weight * total_variation_loss(combination_image)\n","        return loss\n","\n","\n","    @tf.function\n","    def compute_loss_and_grads(combination_image, base_image, style_reference_image):\n","        with tf.GradientTape() as tape:\n","            loss = compute_loss(combination_image, base_image, style_reference_image)\n","        grads = tape.gradient(loss, combination_image)\n","        return loss, grads\n","\n","\n","    base_image = preprocess_image(base_image_path)\n","    style_reference_image = preprocess_image(style_reference_image_path)\n","    combination_image = tf.Variable(preprocess_image(base_image_path))\n","\n","\n","    optimizer = keras.optimizers.SGD(keras.optimizers.schedules.ExponentialDecay(\n","                       initial_learning_rate=100.0, decay_steps=100, decay_rate=0.96))\n","\n","\n","    result_prefix = \"stylised\"\n","    iterations = 2500\n","\n","    for i in range(1, iterations + 1):\n","        loss, grads = compute_loss_and_grads(combination_image, base_image, style_reference_image )\n","        optimizer.apply_gradients([(grads, combination_image)])\n","        if i % 100 == 0:\n","            print(\"Iteration %d: loss=%.2f\" % (i, loss))\n","            img = deprocess_image(combination_image.numpy())\n","            fname = \"stylised_image.png\"\n","            keras.utils.save_img(fname , img)\n","\n","    stylised_image_path = os.path.join(directory, \"stylised_image.png\")\n","    PILImage.open(\"stylised_image.png\").save(stylised_image_path)\n","\n","st.title(\"Neural Style Transfer\")\n","st.markdown(\"\"\"\n","Welcome to the **Neural Style Transfer**! Blending Art and Technology for Creative Images.\n","Upload your **Content Image** and **Style Image** below, then click the 'Style' button to create your own masterpiece!\n","\"\"\")\n","\n","def save_uploaded_file(uploaded_file, filename):\n","    try:\n","        with open(filename, \"wb\") as f:\n","            f.write(uploaded_file.getbuffer())\n","        return True\n","    except Exception as e:\n","        print(e)\n","        return False\n","\n","content_img = st.file_uploader(\"Upload Content Image\", type=[\"png\", \"jpg\", \"jpeg\"])\n","if content_img is not None:\n","    if save_uploaded_file(content_img, \"content_img.png\"):\n","        st.image(content_img, caption=\"Content Image\", use_column_width=True)\n","\n","style_img = st.file_uploader(\"Upload Style Image\", type=[\"png\", \"jpg\", \"jpeg\"])\n","if style_img is not None:\n","    if save_uploaded_file(style_img, \"style_img.png\"):\n","        st.image(style_img, caption=\"Style Image\", use_column_width=True)\n","\n","if st.button(\"Style\"):\n","    st.write(\"Styling in progress...wait for 10-15 minutes\")\n","    NST('content_img.png','style_img.png')\n","    st.write(\"Here is your Masterpiece....\")\n","\n","    styled_image = keras.utils.load_img(os.path.join(\"./gdrive/My Drive/style-transfer\", \"stylised_image.png\"))\n","    st.image(styled_image, caption=\"Styled Image\", use_column_width=True)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"JRGhUo_q9U_7","metadata":{"id":"JRGhUo_q9U_7"},"outputs":[],"source":["!npm install localtunnel"]},{"cell_type":"code","execution_count":null,"id":"pxom9Zyi9U5o","metadata":{"id":"pxom9Zyi9U5o"},"outputs":[],"source":["import urllib\n","print(\"Password/Enpoint IP for localtunnel is:\",urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\"))"]},{"cell_type":"code","execution_count":null,"id":"zIOrybpo9UxO","metadata":{"id":"zIOrybpo9UxO"},"outputs":[],"source":["!streamlit run app.py &>/content/logs.txt &"]},{"cell_type":"code","execution_count":null,"id":"O-o4PHJL9UlJ","metadata":{"id":"O-o4PHJL9UlJ"},"outputs":[],"source":["!npx localtunnel --port 8501"]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}